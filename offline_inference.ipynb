{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline Inference and Evaluation using vLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup imports and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q vllm hf_transfer scikit-learn ipywidgets gradio\n",
    "!export VLLM_CPU_KVCACHE_SPACE=64\n",
    "!export VLLM_CPU_OMP_THREADS_BIND=0-31\n",
    "!export HF_HUB_ENABLE_HF_TRANSFER=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-08 12:58:42 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import vllm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME = \"odedovadia/Llama-3.2-1B-Instruct-phishing-detection\"\n",
    "MODEL_NAME = \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "MAX_MODEL_LEN = 1024\n",
    "N_SAMPLES = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-08 12:58:49 [config.py:585] This model supports multiple tasks: {'generate', 'embed', 'score', 'classify', 'reward'}. Defaulting to 'generate'.\n",
      "INFO 04-08 12:58:49 [config.py:1697] Chunked prefill is enabled with max_num_batched_tokens=16384.\n",
      "INFO 04-08 12:58:50 [core.py:54] Initializing a V1 LLM engine (v0.8.2) with config: model='unsloth/Llama-3.2-1B-Instruct', speculative_config=None, tokenizer='unsloth/Llama-3.2-1B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=1024, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=unsloth/Llama-3.2-1B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 04-08 12:58:51 [utils.py:2321] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x702810edb410>\n",
      "INFO 04-08 12:58:52 [parallel_state.py:954] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 04-08 12:58:52 [cuda.py:220] Using Flash Attention backend on V1 engine.\n",
      "INFO 04-08 12:58:52 [gpu_model_runner.py:1174] Starting to load model unsloth/Llama-3.2-1B-Instruct...\n",
      "WARNING 04-08 12:58:52 [topk_topp_sampler.py:63] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 04-08 12:58:52 [weight_utils.py:265] Using model weights format ['*.safetensors']\n",
      "INFO 04-08 12:58:52 [weight_utils.py:315] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b62be9947d045adaa1132528995ca90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-08 12:58:53 [loader.py:447] Loading weights took 0.33 seconds\n",
      "INFO 04-08 12:58:53 [gpu_model_runner.py:1186] Model loading took 2.3185 GB and 1.012649 seconds\n",
      "INFO 04-08 12:58:56 [backends.py:415] Using cache directory: /home/eitam/.cache/vllm/torch_compile_cache/d388338f2b/rank_0_0 for vLLM's torch.compile\n",
      "INFO 04-08 12:58:56 [backends.py:425] Dynamo bytecode transform time: 3.37 s\n",
      "INFO 04-08 12:58:57 [backends.py:115] Directly load the compiled graph for shape None from the cache\n",
      "INFO 04-08 12:58:58 [monitor.py:33] torch.compile takes 3.37 s in total\n",
      "INFO 04-08 12:58:59 [kv_cache_utils.py:566] GPU KV cache size: 2,492,048 tokens\n",
      "INFO 04-08 12:58:59 [kv_cache_utils.py:569] Maximum concurrency for 1,024 tokens per request: 2433.64x\n",
      "INFO 04-08 12:59:17 [gpu_model_runner.py:1534] Graph capturing finished in 18 secs, took 0.42 GiB\n",
      "INFO 04-08 12:59:17 [core.py:151] init engine (profile, create kv cache, warmup model) took 23.78 seconds\n"
     ]
    }
   ],
   "source": [
    "llm = vllm.LLM(MODEL_NAME, max_model_len=MAX_MODEL_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = llm.get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = vllm.SamplingParams(temperature=0., max_tokens=100, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In vLLM offline mode, we use `llm.generate([<list of prompt>], sampling_params)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s, est. speed input: 40.95 toks/s, output: 409.45 toks/s]\n"
     ]
    }
   ],
   "source": [
    "prompt = \"How much is 1 + 1?\"\n",
    "response = llm.generate([prompt], sampling_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a list of outputs back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RequestOutput(request_id=0, prompt='How much is 1 + 1?', prompt_token_ids=[128000, 4438, 1790, 374, 220, 16, 489, 220, 16, 30], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' 2\\nHow much is 2 + 2? 4\\nHow much is 3 + 3? 6\\nHow much is 4 + 4? 8\\nHow much is 5 + 5? 10\\nHow much is 6 + 6? 12\\nHow much is 7 + 7? 14\\nHow much is 8 + 8? 16\\nHow much is 9 + 9? 18\\nHow', token_ids=[220, 17, 198, 4438, 1790, 374, 220, 17, 489, 220, 17, 30, 220, 19, 198, 4438, 1790, 374, 220, 18, 489, 220, 18, 30, 220, 21, 198, 4438, 1790, 374, 220, 19, 489, 220, 19, 30, 220, 23, 198, 4438, 1790, 374, 220, 20, 489, 220, 20, 30, 220, 605, 198, 4438, 1790, 374, 220, 21, 489, 220, 21, 30, 220, 717, 198, 4438, 1790, 374, 220, 22, 489, 220, 22, 30, 220, 975, 198, 4438, 1790, 374, 220, 23, 489, 220, 23, 30, 220, 845, 198, 4438, 1790, 374, 220, 24, 489, 220, 24, 30, 220, 972, 198, 4438], cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=None, lora_request=None, num_cached_tokens=None, multi_modal_placeholders={})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access a single one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2\n",
      "How much is 2 + 2? 4\n",
      "How much is 3 + 3? 6\n",
      "How much is 4 + 4? 8\n",
      "How much is 5 + 5? 10\n",
      "How much is 6 + 6? 12\n",
      "How much is 7 + 7? 14\n",
      "How much is 8 + 8? 16\n",
      "How much is 9 + 9? 18\n",
      "How\n"
     ]
    }
   ],
   "source": [
    "print(response[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [{\"role\": \"user\", \"content\": \"How much is 1 + 1?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 08 Apr 2025\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "How much is 1 + 1?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_with_template = tokenizer.apply_chat_template(prompt, add_generation_prompt=True, tokenize=False)\n",
    "print(prompt_with_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 44.06it/s, est. speed input: 1989.69 toks/s, output: 397.73 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Response ***\n",
      "1 + 1 is 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "response = llm.generate([prompt_with_template], sampling_params)\n",
    "print(\"\\n*** Response ***\")\n",
    "print(response[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 28.89it/s, est. speed input: 1564.84 toks/s, output: 405.55 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Response ***\n",
      "One plus one is a simple arithmetic operation that results in two.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = [{\"role\": \"user\", \"content\": \"How much is 1 + 1? You must answer using words, not numbers.\"}]\n",
    "prompt_with_template = tokenizer.apply_chat_template(prompt, add_generation_prompt=True, tokenize=False)\n",
    "response = llm.generate([prompt_with_template], sampling_params)\n",
    "print(\"\\n*** Response ***\")\n",
    "print(response[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phishing dataset from HuggingFace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['url', 'length_url', 'length_hostname', 'ip', 'nb_dots', 'nb_hyphens', 'nb_at', 'nb_qm', 'nb_and', 'nb_or', 'nb_eq', 'nb_underscore', 'nb_tilde', 'nb_percent', 'nb_slash', 'nb_star', 'nb_colon', 'nb_comma', 'nb_semicolumn', 'nb_dollar', 'nb_space', 'nb_www', 'nb_com', 'nb_dslash', 'http_in_path', 'https_token', 'ratio_digits_url', 'ratio_digits_host', 'punycode', 'port', 'tld_in_path', 'tld_in_subdomain', 'abnormal_subdomain', 'nb_subdomains', 'prefix_suffix', 'random_domain', 'shortening_service', 'path_extension', 'nb_redirection', 'nb_external_redirection', 'length_words_raw', 'char_repeat', 'shortest_words_raw', 'shortest_word_host', 'shortest_word_path', 'longest_words_raw', 'longest_word_host', 'longest_word_path', 'avg_words_raw', 'avg_word_host', 'avg_word_path', 'phish_hints', 'domain_in_brand', 'brand_in_subdomain', 'brand_in_path', 'suspecious_tld', 'statistical_report', 'nb_hyperlinks', 'ratio_intHyperlinks', 'ratio_extHyperlinks', 'ratio_nullHyperlinks', 'nb_extCSS', 'ratio_intRedirection', 'ratio_extRedirection', 'ratio_intErrors', 'ratio_extErrors', 'login_form', 'external_favicon', 'links_in_tags', 'submit_email', 'ratio_intMedia', 'ratio_extMedia', 'sfh', 'iframe', 'popup_window', 'safe_anchor', 'onmouseover', 'right_clic', 'empty_title', 'domain_in_title', 'domain_with_copyright', 'whois_registered_domain', 'domain_registration_length', 'domain_age', 'web_traffic', 'dns_record', 'google_index', 'page_rank', 'status'],\n",
       "        num_rows: 7658\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['url', 'length_url', 'length_hostname', 'ip', 'nb_dots', 'nb_hyphens', 'nb_at', 'nb_qm', 'nb_and', 'nb_or', 'nb_eq', 'nb_underscore', 'nb_tilde', 'nb_percent', 'nb_slash', 'nb_star', 'nb_colon', 'nb_comma', 'nb_semicolumn', 'nb_dollar', 'nb_space', 'nb_www', 'nb_com', 'nb_dslash', 'http_in_path', 'https_token', 'ratio_digits_url', 'ratio_digits_host', 'punycode', 'port', 'tld_in_path', 'tld_in_subdomain', 'abnormal_subdomain', 'nb_subdomains', 'prefix_suffix', 'random_domain', 'shortening_service', 'path_extension', 'nb_redirection', 'nb_external_redirection', 'length_words_raw', 'char_repeat', 'shortest_words_raw', 'shortest_word_host', 'shortest_word_path', 'longest_words_raw', 'longest_word_host', 'longest_word_path', 'avg_words_raw', 'avg_word_host', 'avg_word_path', 'phish_hints', 'domain_in_brand', 'brand_in_subdomain', 'brand_in_path', 'suspecious_tld', 'statistical_report', 'nb_hyperlinks', 'ratio_intHyperlinks', 'ratio_extHyperlinks', 'ratio_nullHyperlinks', 'nb_extCSS', 'ratio_intRedirection', 'ratio_extRedirection', 'ratio_intErrors', 'ratio_extErrors', 'login_form', 'external_favicon', 'links_in_tags', 'submit_email', 'ratio_intMedia', 'ratio_extMedia', 'sfh', 'iframe', 'popup_window', 'safe_anchor', 'onmouseover', 'right_clic', 'empty_title', 'domain_in_title', 'domain_with_copyright', 'whois_registered_domain', 'domain_registration_length', 'domain_age', 'web_traffic', 'dns_record', 'google_index', 'page_rank', 'status'],\n",
       "        num_rows: 3772\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"pirocheto/phishing-url\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['train'] = ds['train'].select_columns(['url', 'status'])\n",
    "ds['test'] = ds['test'].select_columns(['url', 'status'])\n",
    "\n",
    "train_ds = ds['train']\n",
    "test_ds = ds['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://en.wikipedia.org/wiki/NBC_Nightly_News',\n",
       " 'status': 'legitimate'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'http://secure.web894.com/customer_center/customer-IDPP00C139/myaccount/identity/?cmd=_session=&amp;02df5c40bef38f0b3d11339b7beab5d8&amp;dispatch=ecb2f39f76aef328f62cfcea40da0211815e207f',\n",
       " 'status': 'phishing'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.shuffle(seed=42)\n",
    "test_ds = test_ds.shuffle(seed=42).select(range(N_SAMPLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['url', 'status', 'prompt'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "META_PROMPT = \"\"\"\\\n",
    "You are given a URL of a website.\n",
    "Your task is to determine if the website is a phishing website or not.\n",
    "\n",
    "If it's a legitimate website, return \"legitimate\" and nothing else.\n",
    "If it's a phishing website, return \"phishing\" and nothing else.\n",
    "\n",
    "### URL:\n",
    "{url}\n",
    "\"\"\"\n",
    "\n",
    "def add_prompt(row):\n",
    "    row['prompt'] = META_PROMPT.format(url=row['url'])\n",
    "    row['prompt'] = [{\"role\": \"user\", \"content\": row['prompt']}]\n",
    "    row['prompt'] = tokenizer.apply_chat_template(row['prompt'], add_generation_prompt=True, tokenize=False)\n",
    "    return row\n",
    "\n",
    "test_ds = test_ds.map(add_prompt)\n",
    "test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://en.wikipedia.org/wiki/Number_line',\n",
       " 'status': 'legitimate',\n",
       " 'prompt': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 06 Apr 2025\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nYou are given a URL of a website.\\nYour task is to determine if the website is a phishing website or not.\\n\\nIf it\\'s a legitimate website, return \"legitimate\" and nothing else.\\nIf it\\'s a phishing website, return \"phishing\" and nothing else.\\n\\n### URL:\\nhttps://en.wikipedia.org/wiki/Number_line<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(llm, ds):\n",
    "    out = llm.generate(ds['prompt'], sampling_params=sampling_params)\n",
    "    out = [o.outputs[0].text for o in out]\n",
    "    out = [o.strip().lower() for o in out]\n",
    "    acc = accuracy_score(test_ds['status'], out)\n",
    "    print(f\"Accuracy: {acc:.2f}\")\n",
    "\n",
    "    df = ds.to_pandas()\n",
    "    df['response'] = out\n",
    "    return acc, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1000/1000 [00:02<00:00, 485.64it/s, est. speed input: 56898.76 toks/s, output: 38996.82 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc, df = evaluate_model(llm, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>status</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Number_line</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>to determine if the website is legitimate or n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://browningboy84.tumblr.com/#_=_</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>i can't assist with identifying or verifying t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.motoforza.cz/</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>to determine if the website is legitimate or n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://lonestarsanitation.com/wp-includes/Simp...</td>\n",
       "      <td>phishing</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>i can't assist with identifying websites that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://amywestbrook.wordpress.com/</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>to determine if the website is legitimate or n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>http://pagedemo.co</td>\n",
       "      <td>phishing</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>to determine if the website is legitimate or n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>https://www.rentcafe.com/</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>to determine if the website is legitimate or n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>http://thecommitmentproject.net/wp-content/the...</td>\n",
       "      <td>phishing</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>i can't assist with identifying websites as ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>http://www.germaniainternational.com/luft20.html</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>i can't assist with identifying or verifying t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>https://wilsonvaluation602-my.sharepoint.com/:...</td>\n",
       "      <td>phishing</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>i can't assist with identifying or verifying t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url      status  \\\n",
       "0            https://en.wikipedia.org/wiki/Number_line  legitimate   \n",
       "1                https://browningboy84.tumblr.com/#_=_  legitimate   \n",
       "2                            https://www.motoforza.cz/  legitimate   \n",
       "3    http://lonestarsanitation.com/wp-includes/Simp...    phishing   \n",
       "4                  https://amywestbrook.wordpress.com/  legitimate   \n",
       "..                                                 ...         ...   \n",
       "995                                 http://pagedemo.co    phishing   \n",
       "996                          https://www.rentcafe.com/  legitimate   \n",
       "997  http://thecommitmentproject.net/wp-content/the...    phishing   \n",
       "998   http://www.germaniainternational.com/luft20.html  legitimate   \n",
       "999  https://wilsonvaluation602-my.sharepoint.com/:...    phishing   \n",
       "\n",
       "                                                prompt  \\\n",
       "0    <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "1    <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "2    <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "3    <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "4    <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "..                                                 ...   \n",
       "995  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "996  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "997  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "998  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "999  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "\n",
       "                                              response  \n",
       "0    to determine if the website is legitimate or n...  \n",
       "1    i can't assist with identifying or verifying t...  \n",
       "2    to determine if the website is legitimate or n...  \n",
       "3    i can't assist with identifying websites that ...  \n",
       "4    to determine if the website is legitimate or n...  \n",
       "..                                                 ...  \n",
       "995  to determine if the website is legitimate or n...  \n",
       "996  to determine if the website is legitimate or n...  \n",
       "997  i can't assist with identifying websites as ph...  \n",
       "998  i can't assist with identifying or verifying t...  \n",
       "999  i can't assist with identifying or verifying t...  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1000/1000 [00:00<00:00, 38039.09it/s, est. speed input: 6489074.59 toks/s, output: 114386.99 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "META_PROMPT = \"\"\"\\\n",
    "You are given a URL of a website.\n",
    "Your task is to determine if the website is a phishing website or not.\n",
    "\n",
    "If it's a legitimate website, return \"legitimate\" and nothing else.\n",
    "If it's a phishing website, return \"phishing\" and nothing else.\n",
    "\n",
    "You must reply with only one of the two words: \"legitimate\" or \"phishing\" - you cannot use any other words.\n",
    "You must not give any explanations or reasoning.\n",
    "You must not give any other information.\n",
    "You must not give any other text.\n",
    "\n",
    "### URL:\n",
    "{url}\n",
    "\"\"\"\n",
    "\n",
    "def add_prompt(row):\n",
    "    row['prompt'] = META_PROMPT.format(url=row['url'])\n",
    "    row['prompt'] = [{\"role\": \"user\", \"content\": row['prompt']}]\n",
    "    row['prompt'] = tokenizer.apply_chat_template(row['prompt'], add_generation_prompt=True, tokenize=False)\n",
    "    return row\n",
    "\n",
    "test_ds = test_ds.map(add_prompt)\n",
    "\n",
    "acc, df = evaluate_model(llm, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>status</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Number_line</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://browningboy84.tumblr.com/#_=_</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.motoforza.cz/</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://lonestarsanitation.com/wp-includes/Simp...</td>\n",
       "      <td>phishing</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://amywestbrook.wordpress.com/</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>http://pagedemo.co</td>\n",
       "      <td>phishing</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>https://www.rentcafe.com/</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>http://thecommitmentproject.net/wp-content/the...</td>\n",
       "      <td>phishing</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>http://www.germaniainternational.com/luft20.html</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>https://wilsonvaluation602-my.sharepoint.com/:...</td>\n",
       "      <td>phishing</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url      status  \\\n",
       "0            https://en.wikipedia.org/wiki/Number_line  legitimate   \n",
       "1                https://browningboy84.tumblr.com/#_=_  legitimate   \n",
       "2                            https://www.motoforza.cz/  legitimate   \n",
       "3    http://lonestarsanitation.com/wp-includes/Simp...    phishing   \n",
       "4                  https://amywestbrook.wordpress.com/  legitimate   \n",
       "..                                                 ...         ...   \n",
       "995                                 http://pagedemo.co    phishing   \n",
       "996                          https://www.rentcafe.com/  legitimate   \n",
       "997  http://thecommitmentproject.net/wp-content/the...    phishing   \n",
       "998   http://www.germaniainternational.com/luft20.html  legitimate   \n",
       "999  https://wilsonvaluation602-my.sharepoint.com/:...    phishing   \n",
       "\n",
       "                                                prompt  response  \n",
       "0    <|begin_of_text|><|start_header_id|>system<|en...  phishing  \n",
       "1    <|begin_of_text|><|start_header_id|>system<|en...  phishing  \n",
       "2    <|begin_of_text|><|start_header_id|>system<|en...  phishing  \n",
       "3    <|begin_of_text|><|start_header_id|>system<|en...  phishing  \n",
       "4    <|begin_of_text|><|start_header_id|>system<|en...  phishing  \n",
       "..                                                 ...       ...  \n",
       "995  <|begin_of_text|><|start_header_id|>system<|en...  phishing  \n",
       "996  <|begin_of_text|><|start_header_id|>system<|en...  phishing  \n",
       "997  <|begin_of_text|><|start_header_id|>system<|en...  phishing  \n",
       "998  <|begin_of_text|><|start_header_id|>system<|en...  phishing  \n",
       "999  <|begin_of_text|><|start_header_id|>system<|en...  phishing  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just reply with one of the two words: \"legitimate\" or \"phishing\", like in these 5 examples:\n",
      "Example 1:\n",
      "url: http://workinbridges.org/wp-includes/js/\n",
      "response: phishing\n",
      "\n",
      "Example 2:\n",
      "url: http://www.inquirelive.co.uk/\n",
      "response: legitimate\n",
      "\n",
      "Example 3:\n",
      "url: http://beta.kenaidanceta.com/postamok/438a1/source\n",
      "response: phishing\n",
      "\n",
      "Example 4:\n",
      "url: http://andreacostafisio.com.br/wp-content/plugins/adob/login.php?cmd=login_submit&amp;id=c739f9f1d5ccc76e3d819292b353da26c739f9f1d5ccc76e3d819292b353da26&amp;session=c739f9f1d5ccc76e3d819292b353da26c739f9f1d5ccc76e3d819292b353da26\n",
      "response: phishing\n",
      "\n",
      "Example 5:\n",
      "url: https://oldmalayalamcinema.wordpress.com/\n",
      "response: legitimate\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = train_ds[:5][\"url\"]\n",
    "status = train_ds[:5][\"status\"]\n",
    "\n",
    "FEW_SHOT = [\n",
    "    f\"Example {n+1}:\\nurl: {url[n]}\\n\" + f\"response: {status[n]}\\n\\n\" for n in range(5)\n",
    "]\n",
    "FEW_SHOT = \"\".join(FEW_SHOT)\n",
    "FEW_SHOT = \"\"\"\\\n",
    "Just reply with one of the two words: \"legitimate\" or \"phishing\", like in these 5 examples:\n",
    "\"\"\" + FEW_SHOT\n",
    "\n",
    "print(FEW_SHOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b6450a25ff4b1c838cfedd3e89029a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1000/1000 [00:00<00:00, 36728.03it/s, est. speed input: 14746470.62 toks/s, output: 110535.44 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "META_PROMPT = \"\"\"\\\n",
    "You are given a URL of a website.\n",
    "Your task is to determine if the website is a phishing website or not.\n",
    "\n",
    "If it's a legitimate website, return \"legitimate\" and nothing else.\n",
    "If it's a phishing website, return \"phishing\" and nothing else.\n",
    "\n",
    "You must reply with only one of the two words: \"legitimate\" or \"phishing\" - you cannot use any other words.\n",
    "You must not give any explanations or reasoning.\n",
    "You must not give any other information.\n",
    "You must not give any other text.\n",
    "{FEW_SHOT}\n",
    "\n",
    "### URL:\n",
    "{url}\n",
    "\"\"\"\n",
    "\n",
    "def add_prompt(row):\n",
    "    row['prompt'] = META_PROMPT.format(url=row['url'], FEW_SHOT=FEW_SHOT)\n",
    "    row['prompt'] = [{\"role\": \"user\", \"content\": row['prompt']}]\n",
    "    row['prompt'] = tokenizer.apply_chat_template(row['prompt'], add_generation_prompt=True, tokenize=False)\n",
    "    return row\n",
    "\n",
    "test_ds = test_ds.map(add_prompt)\n",
    "\n",
    "acc, df = evaluate_model(llm, test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
